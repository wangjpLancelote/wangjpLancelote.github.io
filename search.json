[{"title":"Defi(去中心化金融)","url":"/2024/03/26/Defi/","content":"什么都没留下"},{"title":"GameFi(Defi的游戏化)","url":"/2024/03/26/GameFi/","content":"什么都没留下"},{"title":"Redux-Middleware","url":"/2024/03/26/Redux-middleware/","content":"Redux-Middleware 解析\n💡 It provides a third-party extension point between dispatching an action, and the moment it reaches the reducer.\n\n\n\n以上是 Dan Abramov 对 middleware 的描述，他提供了一个分类处理 action 的机会，在 middleware 中，你可以检阅每一个流过的 action，挑选出特定类型的 action 进行相应操作，给你一次改变 action 的机会，\n看一下使用方法：\nimport &#123; Middleware &#125; from &quot;react&quot;;export const logger: Middleware = (store) =&gt; (next) =&gt; (action) =&gt; &#123;  console.log(action);  return next(action);&#125;;// 这里用了函数科里化的做法，将每个return的函数都改成一个参数的函数，为了解耦\n\nMiddleware 具体是如何实现的呢\nexport default function applyMiddleware(...middlewares) &#123;  return (createStore) =&gt; (reducer, preloadedState, enhancer) =&gt; &#123;    var store = createStore(reducer, preloadedState, enhancer);    var dispatch = store.dispatch;    var chain = [];    var middlewareAPI = &#123;      getState: store.getState,      dispatch: (action) =&gt; dispatch(action),    &#125;;    chain = middlewares.map((middleware) =&gt; middleware(middlewareAPI));    dispatch = compose(...chain)(store.dispatch);    return &#123;      ...store,      dispatch,    &#125;;  &#125;;&#125;\n\n了解一下 compose 函数：\nlet result = compose(f1, f2, f3, f4)(value) -&gt; let result = f1(f2(f3(f4(value))))\n\n其中\nchain = middlewares.map(middleware =&gt; middleware(middlewareAPI))dispatch = compose(...chain)(store.dispatch)// 可以变化为fnMiddle = fn(middlewareAPI)dispatch = fnMiddle(store.dispatch)//也就是dispatch = fn(middlewareAPI)(store.dispatch)//接着store.dispatch(action)// 等价于fn(middlewareAPI)(store.dispatch)(action)// 那么dispatch = compose(...chain)(store.dispatch) === dispatch = fn1Middle(fn2Middle(store.dispatch))// 每一次fnMiddle执行之后，就会返回一个函数(action) =&gt; &#123;\t...\tnext(action)\t...&#125;// 到了下一个fnMiddle执行的时候，接受一个传入的action参数，方法体里执行的是next(action)// 那么，什么事next方法呢，由第一个fnMiddleware执行的时候传入store.dispatch()// store.dispatch 就作为next函数的方法体// 也就是，每次的next(action)实际上就是执行的store.dispatch(action)\n\n\n以上的图示表明，redux 的 middleware 是多层函数包裹结构，每个 middleware 执行完之后，就会将结果返回给下一个 middleware，其中 return 的函数参数为 action，函数体会执行 next(action)，而 next 正是第一次传入 store.dispatch，因为这里是用了 compose 编程思想，将不变的函数参数以科里化的形式作为参数传入，如 store，next，而变化的参数如 action 则作为最后一个参数传入，形如：\nmiddleware = (store) =&gt; (next) =&gt; (action) =&gt; &#123;&#125;;// store, next 都是不变的函数参数，action作为每个middleware需要处理的对象，最后一个传入\n"},{"title":"Farm(耕种)","url":"/2024/03/26/farm/","content":"Yield Farming(流动性挖矿) [  Yield(收益), Farm(耕种)，指将资金投入到不同的Defi协议中赚取回报 ]"},{"title":"Web3.0","url":"/2024/03/26/hello-world/","content":"什么都没留下"},{"title":"Lend(借贷)","url":"/2024/03/26/lend/","content":"什么都没留下"},{"title":"Oracle(预言机)","url":"/2024/03/26/oracle/","content":"预言机(Oracle)什么是预言机？\n\n预言机是指数据馈送，它提取区块链数据源（下链）的数据并将数据存放到区块链（上链）上供智能合约使用。因为运行在以太坊上的智能合约无法访问存储在区块链网络之外的信息，预言机是必不可上的。\n预言的意思（Oracle）是指古希腊神话中的神谕，由神或者女祭司发表的预言或指示，因此，这里将外部数据引入区块链的机制被称为 Oracle，即预言机\n预言机赋予了智能合约使用链下数据输入执行的能力，扩展了去中心化应用的价值，例如，去中心化预测市场依靠预言机提供的关于结果的信息，并且能够使用这些信息验证用户的预测。假设 A 下注了 20 个以太币赌谁将成为下一任美国总统，这种情况，链上的数据中是没有关于下一任总统的信息的，预测市场去中心化应用程序需要预言机来确认选举结果，并判定 A 是否有资格获得赌注\n区块链预言机获取验证外部信息（即存储在链下的信息）并将外部信息传送给区块链上运行的智能合约的应用程序。除了拉取链下数据用户并在以太坊进行广播之外，预言机还将信息从区块链推送到外部系统，用户通过以太坊交易发送费用后解锁智能锁的预言机就是一个推送信息的示例。\n预言机充当了一座桥梁，链接区块链上的智能合约与链下数据提供者，如果没有预言机，智能合约智能访问链上的数据，预言机提供了一种使用链下数据处罚智能合约的功能机制。\n预言机的分类：\n\n数据来源（一种或多种）\n信任模型（中心化&#x2F;去中心化）\n系统架构（立即读取或发布订阅）\n是否检索外部数据供链上合约使用（输入预言机）\n是否将区块量的信息发送给链下应用程序（输出预言机）\n在链下执行计算任务（计算预言机）\n\n预言机解决了什么问题智能合约不仅仅只是作为区块链特定地址运行的代码段，更广义来说，智能合约是指满足特定条件后能够执行各方之间协议的自执行软件程序\n但是问题也在于此，因为以太坊是确定性系统，确定性系统是指在给定初始状态和特定输入时总是产生相同结果的系统，即在使用输入计算输出的过程中不存在随机性和变化\n要实现确定性执行，区块链节点限制为通过仅使用存储在区块链本身中的数据就简单的二进制(true&#x2F;false)问题达成共识，这类问题的示例包括：\n\n账户所有者（由公钥识别）是否使用配对私钥签署该交易\n该账户是否有足够资金支付这笔交易\n这笔交易在该智能合约中是否有效\n\n如果区块链从外部来源（现实世界）接受信息，确定性将不可能实现，阻止节点就区块链状态变化的有效性达成一致，以一个智能合约为例，该合约根据从一个传统价格应用程序接口获得的当前的以太币-美元（ETH&#x2F;USDT）汇率窒执行交易。该汇率会经常变动，甚至会被弃用会黑客攻击，这意味着执行相同合约代码的节点会得出不同的结果\n全球会数千个节点处理交易的公共区块链，如以太坊，确定性至关重要，由于没有中心化阻止作为真实性来源，期望节点在进行相同交易后达到相同状态。节点 A 执行智能合约的代码得到结果“3”，而 B 节点运行相同交易后得到“7”，这将打破共识并消除以太坊作为去中心化计算平台的价值。\n以上就是区块链从外部来源获取信息的问题\n预言机解决了这一问题，它从链下来源获取信息并存储在区块链上供智能合约使用。由于存储在链上的信息是不可更改和公共可用的，以太坊节点可以安全地使用预言机导入的链下数据计算状态变化。\n为此，预言机通常由链上运行的智能合约和一些链下组件构成。链上合约接收其他智能合约的数据请求，并将这些请求传送给链下组件（称为预言机节点）。这类预言机节点可以查询数据源-例如使用 API 并发送交易将请求的数据存储在智能合约的存储中。\n总结就是：预言机弥合了区块链和外部环境（如真实世界）的信息缺口，创建了混合智能合约，原理是基于链上合约代码和链下基础设施的结合。\n什么是预言机问题如何依赖一个实体或多个实体向区块链引入外部信息（即将信息存储在交易的数据有效负载中），智能合约很容易获取链下数据，但是会有新的问题：\n\n如何验证注入信息是从正确来源提取的或者未被篡改\n如何确保这些数据始终可用且定期更新。\n\n重要的是确保来自预言机的数据是正确的，否则智能合约执行会产生错误结果，这是一个信任问题\n不同的预言机在解决预言机问题方面采取的方法各不相同，只需要满足以下几点的中几个即可：\n\n正确性：预言机不应导致智能合约基于无效的链下数据触发状态变化。因此，预言机必须保证数据的真实性和完整性-真实性是指数据从正确来源获取，完整性是指数据在发送到链上前保持完好无缺。\n可用性：预言机不应延迟或阻止智能合约执行操作或触发状态变化，该特点要求预言机提供的数据在请求时可用并且不会出现间断。\n激励兼容性：预言机激励链下数据提供者向智能合约提交正确的信息。包括可归因性和问责性，可归因性允许将一条外部信息与其提供者关联起来，问责性指的是数据提供者与提供的信息绑定，这样就可以根据所提供信息的质量对他们进行奖励或惩罚。\n\n预言机合约预言机合约是预言机服务的链上组成部分，它侦听其他合约发出的数据请求，将数据查询转发到预言机及诶单并将返回的数据向客户端合约广播，该合约还可以对返回的数据点进行一些计算，以产生聚合值并发送给请求合约。\n以下是合约示例\npragma solidity &gt;=0.4.21 &lt;0.6.0;contract Oracle &#123;  Request[] requests; //list of requests made to the contract  uint currentId = 0; //increasing request id  uint minQuorum = 2; //minimum number of responses to receive before declaring final result  uint totalOracleCount = 3; // Hardcoded oracle count  // defines a general api request  struct Request &#123;    uint id;                            //request id    string urlToQuery;                  //API url    string attributeToFetch;            //json attribute (key) to retrieve in the response    string agreedValue;                 //value from key    mapping(uint =&gt; string) answers;     //answers provided by the oracles    mapping(address =&gt; uint) quorum;    //oracles which will query the answer (1=oracle hasn&#x27;t voted, 2=oracle has voted)  &#125;  //event that triggers oracle outside of the blockchain  event NewRequest (    uint id,    string urlToQuery,    string attributeToFetch  );  //triggered when there&#x27;s a consensus on the final result  event UpdatedRequest (    uint id,    string urlToQuery,    string attributeToFetch,    string agreedValue  );  function createRequest (    string memory _urlToQuery,    string memory _attributeToFetch  )  public  &#123;    uint length = requests.push(Request(currentId, _urlToQuery, _attributeToFetch, &quot;&quot;));    Request storage r = requests[length-1];    // Hardcoded oracles address    r.quorum[address(0x6c2339b46F41a06f09CA0051ddAD54D1e582bA77)] = 1;    r.quorum[address(0xb5346CF224c02186606e5f89EACC21eC25398077)] = 1;    r.quorum[address(0xa2997F1CA363D11a0a35bB1Ac0Ff7849bc13e914)] = 1;    // launch an event to be detected by oracle outside of blockchain    emit NewRequest (      currentId,      _urlToQuery,      _attributeToFetch    );    // increase request id    currentId++;  &#125;  //called by the oracle to record its answer  function updateRequest (    uint _id,    string memory _valueRetrieved  ) public &#123;    Request storage currRequest = requests[_id];    //check if oracle is in the list of trusted oracles    //and if the oracle hasn&#x27;t voted yet    if(currRequest.quorum[address(msg.sender)] == 1)&#123;      //marking that this address has voted      currRequest.quorum[msg.sender] = 2;      //iterate through &quot;array&quot; of answers until a position if free and save the retrieved value      uint tmpI = 0;      bool found = false;      while(!found) &#123;        //find first empty slot        if(bytes(currRequest.answers[tmpI]).length == 0)&#123;          found = true;          currRequest.answers[tmpI] = _valueRetrieved;        &#125;        tmpI++;      &#125;      uint currentQuorum = 0;      //iterate through oracle list and check if enough oracles(minimum quorum)      //have voted the same answer has the current one      for(uint i = 0; i &lt; totalOracleCount; i++)&#123;        bytes memory a = bytes(currRequest.answers[i]);        bytes memory b = bytes(_valueRetrieved);        if(keccak256(a) == keccak256(b))&#123;          currentQuorum++;          if(currentQuorum &gt;= minQuorum)&#123;            currRequest.agreedValue = _valueRetrieved;            emit UpdatedRequest (              currRequest.id,              currRequest.urlToQuery,              currRequest.attributeToFetch,              currRequest.agreedValue            );          &#125;        &#125;      &#125;    &#125;  &#125;&#125;\n\n预言机的节点的常见任务是，想 api 发送请求，解析响应以提取相关数据，设置为区块链可读的输出格式，并通过将输入包含在预言机合约的交易中将其发送到链上，在利用“真实性证明”证明所提交信息的有效性和完整性时，可能也会用到预言机节点。\n预言机类型：\n\n中心化预言机，由单体控制，该实体负责聚合链下信息并按照请求更新预言机合约的数据，中心化预言机效率高，因为他们依赖单一真实性来源，在专有数据集由所有者直接发布且有公认签名的情况下，中心化预言机可能是更好的选择。但是存在低正确性保障和可用性差的问题，中心化预言机的提供者如何关闭服务或者遭遇了黑客的攻击的话，智能合约会面临 Dos 攻击的风险\n去中心化预言机，会尝试不同的方法实现数据的正确性，其中包括使用证明来证明返回信息的真实性和完整性。\n\n预言机的应用\n检索金融数据DeFi 应用允许 p2p 贷款，借贷和资产交易，需要获取不同的金融信息，包括汇率数据的资本市场数据，常用的如：Chainlink price Feeds、Compound Protocol 的开放式喂价工具、Uniswap 的时间加权平均价格(TWAP)\n生成可验证的随机性某些区块链的应用程序（如基于区块链的游戏或彩票方案），需要高度的不可预测性和随机性才能工作，然而，区块链的确定性执行消除了任何随机来源通常方法是伪随机密码函数，例如 blockhash，但是以太坊过渡到权益证明意味着不能再依靠 blockhash 获得链上随机性。可以在链下生成随机值并发送到链上，但这样做对用户有很高的信任要求，他们必须相信值确实是通过不可预测的机制产生的，并且在传输过程中未被改动。计算预言机则可以解决这一问题，可以安全的生成链下随机结果并连同证实该过程不可预测性的加密证明一起在链上广播。\n获取事件结果预言机可以创建响应真实事件的智能合约，预言机服务可以允许合约通过链下组件连接到外部应用程序接口并使用来自这些数据源的信息。\n智能合约自动化\n\n预言机应用\nChainlink\nWitnet\nUMA 预言机\nTellor\nBand Protocol\nProvable\nParalink\nDos.Network\nPyth\n\n"},{"title":"Liquidity(流动性)","url":"/2024/03/26/liquidity/","content":"什么都没留下"},{"title":"Gitlab-Runners 配置","url":"/2024/03/26/runners/","content":"gitlab-runners 流程配置项目部署的流程如下:\n\n将项目打包(build)\n启动 web 服务器（如 nginx）\n将打包后的文件上传到 web 服务器的指定目录下例如：scp -r .&#x2F;buildDir&#x2F;* 目标服务器名称@目标服务器 ip:目标服务器下 nginx 的 root 配置目录，在当前目录下执行\n重启 nginx（或者其他 web 服务器）\n\ngitlab-CICD 就是要将以上的流程自动化，推送项目代码之后就能自动执行这些流程步骤。\n使用 gitlab-runner 作为执行构建任务的执行器\n首先安装 gitlab-runner\n\nbash 安装。2. docker 安装。3. 官网安装包下载\n\n\nbash 安装\n\n# bash 安装sudo apt-get updatesudo apt-get install gitlab-runner\n\n\ndocker 安装\n\n# docker 安装# 拉取镜像docker pull gitlab/gitlab-runner# 启动容器docker run -d --name gitlab-runner --restart always \\  -v /opt/gitlab-runner/config:/etc/gitlab-runner \\  -v /var/run/docker.sock:/var/run/docker.sock \\  gitlab/gitlab-runner:latest# 进入容器docker exec -it gitlab-runner bash\n\n\n安装包安装\n\nhttps://docs.gitlab.com/runner/install/linux-repository.html\n# 版本较低sudo wget -O /usr/local/bin/gitlab-runner https://gitlab-ci-multi-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-ci-multi-runner-linux-amd64# 添加执行权限sudo chmod +x /usr/local/bin/gitlab-runner# 创建gitlab runner用户sudo useradd --comment &#x27;GitLab Runner&#x27; --create-home gitlab-runner --shell /bin/bash\n\n\n注册 runner(可注册多个不同 token 的 runners)\n\n注册gitlab runner# 在容器内或者服务器内执行sudo gitlab-runner register# 注册过程需要提供一些信息\t- gitlab 实例的url\t- 注册token，可以在gitlab的runner设置页面中获取\t- runner的描述\t- runner的标签(tags)\t- 是否允许runner在没有tag的作业上运行\n\n\n配置 gitlab-runner，在&#x2F;etc&#x2F;gitlab-runner&#x2F;config.toml 文件中进行,主要配置一些并发作业数，日志级别等\n\n\n启动 runner\n\nsudo gitlab-runner startsudo gitlab-runner restart\n\n出现以下提示说明已经成功了\nRuntime platform  arch=amd64 os=linux pid=55297 revision=656c1943 version=16.9.0\n\n\n验证 runner 配置\n\nsudo gitlab-runner verify\n\n\nrunner 设置完成之后，进入到 gitlab，点击查看 CICD 部分，可以看到注册好的 runner，然后在项目中添加配置文件.gitlab-ci.yml\n\nstages: # List of stages for jobs, and their order of execution  - install  - build  - deployvariables:  NPM_REGISTRY: https://registry.npm.taobao.orgcache:  key: $&#123;CI_COMMIT_REF_SLUG&#125;  paths:    - node_modules/install-job:  stage: install  # image: node:latest  script:    - echo &quot;starting install packages&quot;    # - npm install    - echo &quot;Complete installed packages&quot;  only:    - main # 仅在main分支部署build-job: # This job runs in the build stage, which runs first.  stage: build  image: node:latest  dependencies:    - install-job # 确保在 build 之前运行 install 作业  script:    - echo &quot;Start Building the code...&quot;    - npm install    - npm run build    - echo &quot;Building Code complete.&quot;  artifacts:    paths:      - out/  only:    - main # 仅在main分支部署deploy-job: # This job runs in the deploy stage.  stage: deploy # It only runs when *both* jobs in the test stage complete successfully.  image: alpine:latest  dependencies:    - build-job  before_script:    - sed -i &#x27;s/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g&#x27; /etc/apk/repositories    - apk update    - apk add --no-cache openssh-client    - mkdir -p ~/.ssh    - chmod 700 ~/.ssh    - echo &quot;$&#123;SSH_PRIVATE_KEY&#125;&quot; &gt; ~/.ssh/id_rsa    - chmod 600 ~/.ssh/id_rsa    - ls out/  script:    - echo &quot;Deploying application...&quot;    - scp -r -o &quot;StrictHostKeyChecking=no&quot; ./out/* root@10.131.130.113:/home/wiki/    - echo &quot;Files copied, restarting Nginx...&quot;    - ssh -o &quot;StrictHostKeyChecking=no&quot; $SSH_ROOT@$SSH_HOST &quot;sudo nginx -s reload&quot;    - echo &quot;Application successfully deployed.&quot;  only:    - main # 仅在main分支部署\n\n\n配置完成之后，通过 git push origin main 就会触发构建任务install → build → deploy\n\ndeploy 阶段有 scp 和 nginx restart 操作\nscp 首先要在 alpine 镜像构建容器的时候先进行 ssh 密钥对认证\n\n在容器内部新建.ssh 目录，\n将 gitlab 的秘密变量私钥 SSH_PRIVATE_KEY 复制到.ssh&#x2F;id_rsa 文件，\n在部署服务器中的.ssh&#x2F;authrization_key，添加对应的公钥，目的是为了 ssh 免密码登录\n\n然后进行 scp 复制构建产物到服务器的对应目录\n重启 web 服务器\ngitlab-runner cicd 流程结束，代码部署成功\n# nginx.conf示例server &#123;        listen  8000;        server_name     localhost;        charset utf-8;        #charset koi8-r;        #access_log  logs/host.access.log  main;        add_header Content-Security-Policy &quot; object-src &#x27;none&#x27;; script-&#x27;self&#x27; &#x27;unsafe-inline&#x27; &quot;;        add_header  X-Frame-Options SAMEORIGIN;        add_header X-Content-Type-Options nosniff;        location / &#123;          root  /home/wiki; # /home/wiki 就是前端资源部署的位置          try_files $uri $uri/ /index.html;          index index.html index.htm;        &#125;    &#125;\n"},{"title":"SmartContract(智能合约)","url":"/2024/03/26/smartContract/","content":"\n💡 智能合约是部署在链上的，具有公开透明，不可篡改的特性\n\n\n智能合约是一种运行在以太坊链上的程序，它是位于以太坊区块链上的一个特定地址的一系列代码（函数）和数据（状态）。智能合约也是一个以太坊账户，我们称之为合约账户，这意味着它有余额，可以通过网络进行交易，但是，它无法被人为操控，他们是被部署在去中心化节点上作为网络节点作为程序运行着。个人用户可以通过提交交易执行智能合约的某个函数来与智能合约进行交互。智能合约是一个按照特定规则编写的代码文件，并通过代码自动强制执行。\n特色无需许可，任何人都编写智能合约并将其部署到区块链网络上，你只需要学习如何用智能合约编码规则，并且有足够的 ETH 来部署你的合约，在技术上，部署智能合约是一项交易，所以需要支付 Gas Fee，就像为以太坊转账一样，需要消耗 Gas 一样。但是，部署合约需要消耗更多的 Gas\n语言\nSolidity：类 JavaScript 语言\nVyper：类 Python 语言\n\n局限性智能合约本身无法获取关于“真实世界”的事件信息，因为他们无法发送 HTTP 请求，这样设计是因为依赖于外部信息可能会危及共识，这对安全性和去中心化而言非常重要。\n而需要获取外部信息，可以通过预言机实现\n智能合约可以简单理解为可执行的公开透明的程序，被开发者部署到以太坊区块链上，与外界完全隔离并运行与以太坊虚拟机（EVM），这样就脱离了认为干预，完全只按照代码设定的规则运行\n区块链技术的出现不仅解决了该概念里最重要的合约对货币的百分之百的控制权，并且可编程的优势又让他秒杀了一切传统合约，而区块链的去中心化、不可篡改、过程透明可追踪等优点，更是令智能合约如虎添翼，一飞冲天。\n智能合约是纯正且原生的区块链技术，它符合我们对于区块链价值观的所有期望\n"},{"title":"Stake(质押)","url":"/2024/03/26/stake/","content":"什么都没留下"},{"title":"Token(通证)","url":"/2024/03/26/token/","content":"Web3 中的 Token 的作用：\n\n代币：ERC20 类型的通证基本都属于这种类型，可用于众筹，债券发行，商品与服务的买卖，其总市值代表一个项目的总资产合总价值\n金融工具与金融衍生品\n所有权令牌：ERC721 代币属于这种类型\n激励工具：如比特币\n安全保障手段：如比特币、ETH\n投票权：如 EOS\n股权证书\n门票或通行证\n自治组织(DAO)的治理工具\n\n什么是同质化和非同质化通证呢\n同质化：具有相同的某种特质或某个种类，那么就会认为是同质化的，每个个体之间没有差别，每个个体之间的价值完全相同，可以互相交换，如代币之间就属于同质化通证\n非同质化：不同物品之间具有独特、不可替代、不可互换这些特性的话，就满足了非同质化通证的特点，如艺术作品、人、游戏角色、房产等\n以太坊不同通证的标准\n\n\nERC20\n可替换资产的原始代币合约\n\n\n\nERC-165\n创建标准方法以发布和检测只能合约的借口\n\n\nERC-173\n合同所有权的标准接口\n\n\nERC-223\n向后兼容 ERC-20，保护投资者以防意外的转账\n\n\nERC-721\n非同质化代币(NFTs)标准，可作为产权进行交易\n\n\nERC-725\n密钥管理和执行的代理合同，简历区块链身份\n\n\nERC-777\n基于操作者的代币标准，具有高度可定制性\n\n\nERC-809\n非同质化的租赁标准，用户可使用一系列指令来出租 NFTs\n\n\nERC-827\n允许转让通证并允许持有人允许第三方使用通证\n\n\nERC-864\nNFTs 共有产权，旨在 NFT 合约中分享 NFT 的所有权\n\n\nERC-865\n此项标准允许用户委托第三方帮忙转账，并以代币形式支付 Gas 费用\n\n\nERC-918\n可开采性代币，允许加入挖矿算法\n\n\nERC-874\n加权的不可替代代币，便于了解到独特的资产拥有的价值\n\n\nERC-888\n多维代币标准，使用标识符代表余额和数据\n\n\nERC-998\n可拆解非同质化代币，可包含多个 ERC-721 和 ERC-20 的形式\n\n\nERC-1067\n可升级代币合约的标准，提供代币在合约在内的多种用途的事件锁仓功能\n\n\nERC-1132\n代币锁定能力的标准，提供代币在合约多种用途的事件锁仓功能\n\n\nERC-1155\n多代币标准，可追踪多个代币余额和所有权的合约，及定义多个物品\n\n\nERC-1178\n多级别代币的标准，为多个级别的代币的合约提供标准接口\n\n\nERC-1190\n非同质化版税代币标准，可向创造者以及&#x2F;或者所有者支付版税\n\n\nERC-1203\n多层级代币标准，提供多层级代币合约的标准接口\n\n\nERC-1238\n不可转账代币标准，代表徽章的不可转账代币\n\n\nERC-1400\n证券通证标准，部分可互换代币，该 EIP 标准具有能力进行强制转移\n\n\nERC-1404\n为证券通证、通证化证券以及其他携带复杂要求的其他通证儿准备\n\n\nERC-2612\n该标准可以取消 ERC-20 的 approve + transform，同时海允许无 Gas 通证转账\n\n\nMinime Token\n带更多功能的 ERC-20 代币（易克隆），获得余额转账历史及代币控制\n\n\n"},{"title":"前端项目部署","url":"/2024/03/26/%E5%89%8D%E7%AB%AF%E9%83%A8%E7%BD%B2/","content":"大公司如何开发部署前端代码\n多人协作模式下的前端代码开发、超大流量访问下的前端应用的部署\n\n\n多人协作开发这个比较基础、主要是代码管理方面，使用 git 或者 svn，按照一定的 flow，如从 dev 分支下切新分支进行开发、开发完成之后提测，发起合并请求，合并到测试分支，当测试完成之后继续提交合并请求，上线\n大型网站主站的前端应用部署分析一下，部署前端代码到底做了什么呢？主要做的事情就是将静态文件如 index.html、index.js、index.css 放到具体的静态资源服务器上，常见的如 nginx，随后重启服务，部署就完成了，用户要访问最新的应用，刷新页面就可以了，这个过程非常简单。但是问题来了，如果一个网站流量非常大，这样做的话就会出现，光是这三个文件(实际上远不止三个文件)的加载消耗的流量就是天量的数字，非常浪费性能。通常这种问题我们会想到利用浏览器的缓存机制来优化，事实上浏览器的缓存就是这么用的\n304 协商缓存\n协商缓存还是存在一次与服务器通信过程，我们的目的就是彻底取消与服务器的通信，因此放弃\n\n强缓存\n强缓存倒是不用通信了，但是不和服务器通信的话，如何更新资源呢，毕竟每次更新的目的都是要让用户去使用我们的产品，这时候可以用更新文件资源路径来让浏览器主动放弃缓存，每一次更新，都自动更新链接地址\n\n\n以上第二种方式可以达到我们的目的，但是也存在一个问题，我们每次更新不能修改所有的文件链接地址，需要知道当前的更新是哪个文件，并且只修改对应的文件地址就好了\n\n更新对应修改文件的链接地址\n\n\n\n如何知道修改了哪个静态资源文件呢，也就是什么东西与文件内容有关呢，可以利用 Hash 算法，将文件内容 hash 成一个字符串内容，hash 算法可以根据每次不同的文件内容生成不同字符串，因此就达到了控制单文件粒度的目的。\n这个对文件内容 hash 化的过程，通常是由构建工具完成的，如 webpack、vite、rollup 等等在打包 build 的时候就会处理好，继而将对应的文件路径添加到 html 中。\n\n💡 如果要再继续优化网站性能呢\n\n\n\n使用 CDN，内容分发网络，将静态资源和动态网页分集群部署，具体是将需要部署的网站主站页面 index.html（动态网页）部署到部署服务器中，将网页包含的静态资源（如 a.js，b.css）部署到 CDN 节点上，最后将 CDN 映射的域名链接添加到动态网页中。\n\n💡 解决完了静态资源和网页的性能问题之后，新的问题出现了，如果同时修改了网页和资源，到底是先部署网页还是先部署资源\n\n\n\n\n先部署页面，后部署资源；那么在二者部署的间隔内，有用户访问页面(大型系统的主站每时每刻都有人访问)，会在新的页面加载旧的资源，除非是手动刷新，否则在资源缓存过期之前，页面会一直执行错误\n先部署资源，后部署页面；那么在二者部署的间隔内，有旧版本资源本地缓存的用户访问页面，请求的页面也是旧版本的，资源引用没有改变，页面展示正常，而没有本地缓存后者缓存过期的网站，就会出现旧版本页面访问新版本资源的情况，导致页面执行错误（一般是样式错位），除非等到页面部署完成，才能恢复正常。\n\n以上问题说明，先部署都不行，都会有两者的部署间隔期，如果访问量不大的话，可以在访问低谷期部署，也就是半夜上线，这样对流量访问影响最小，但是大型网站，门户网站，主站这些流量很大且没有明显低谷期的网站，就不能通过这种方式发布了；因此以上的问题的根源就是发布的时候旧资源会被丢弃，导致访问不到对应的内容\n\n💡 既然问题是由发布之后访问不同版本资源错位造成的，那么能不能让未刷新页面的人用旧版本资源和页面，新访问的用户访问新版本的资源和页面呢？可以，也就是发布的时候不要覆盖旧版本的内容，这种方式叫非覆盖式发布或者滚动发布\n\n\n\n内容有修改的文件的资源对其 hash 计算得到一个新的 hash 值，上传到 CDN 节点上，生成成一个新的文件链接发布到线上，不会覆盖已有的资源文件，上线过程中，先全量部署静态资源，再灰度部署页面。问题就解决的差不多了。\n总结下来就是：\n\n配置超长时间的本地缓存，节省带宽，提高性能\n采用内容摘要作为内容更新的依据，精确控制更新的文件\n静态资源 CDN 部署\n更新资源发布路径采用滚动式发布，平滑升级\n\n\n发布完之后，如果遇到发布代码有问题，需要马上回滚，最好是秒级会滚，应该如何做呢\n\n重新打包部署不现实，因为这个时间太久了，很有可能用户已经访问了错误的页面，最好的方案是能够切换路由到上一个版本，从入口处解决，这个时候就需要在资源链接上增加一个版本号的概念：?version&#x3D;1.x.x，通过指定渲染哪个版本号的资源就可以达到秒级回滚页面内容的效果。\n这里的 version 号可以根据业务来确定，如每次部署都会有一个业务号，每次部署的业务号自增，需要回滚的时候，只需要根据版本号自动切换即可，这个切换最好是在网关处处理，这也意味着滚动式发布是生产环境的最适合的方案，具有容灾备份的效果。\n\n以上是属于代码 build 之后进行 deploy 的过程，除此之外，部署的过程还有代码完成之后到 build 这个过程，下面就介绍一下这个过程：CiCd\n\nci&#x2F;cd：持续交付&#x2F;持续部署，意思是新增代码后的自动校验格式，打包，构建，跑单元测试，提供单元测试覆盖率，出具报告，之后在进行代码自动部署，目的是简化重复的工作，且不会出错。\n常见方案：\n\nJenkins\nGitlab-ci actions\nDocker + K8s\n自己搭建构建服务器\n\n\n线上部署期间，用户长时间没有访问网页等各种情况，有一定概率出现错误Uncaught ChunkLoadError: Loading chunk &lt;CHUNK_NAME&gt; failed. 这个错误是说无法加载资源文件，可能是资源文件名错误,这种情况会导致网页白屏\n\n原因在于现在前端构建工具 webpack 打包出来的项目，主入口(index.html)默认不缓存，其他文件长期缓存，缓存的文件通过改变文件名(hash)来更新，所以在部署期间长期没有访问，会出现请求的资源路径已被删除，或者虽然路径没变，但是 chunk 的内容改变了，导致出现的白屏，\n有一下方案：\n\n缓存所有版本的文件，空间占用太大\n打包出来的文件不做缓存，对服务器压力很大\n通过 websocket 等轮询的方式主动告知浏览器更新版本，（也就是刷新页面）需要后端支持\n对于报错的文件重试，超过一定次数白屏，主动告知用户刷新页面\n\n综上，采用最后一种方案\n缓存重试一定次数后弹窗提示用户刷新页面，借助 webpack-retry-chunk-load-plugin 插件和 html-tag-attribute-plugin 插件配合使用\n通常重试的文件不需要全部类型，仅仅需要重试 js 文件即可\nRetry-chunk-load 方案\n"},{"title":"区块链钱包","url":"/2024/03/26/wallet/","content":"\n\n什么是区块链钱包&emsp;区块链钱包是加密货币应用中必不可少的一部分，也是加密基础设施中最基础的一部分，区块链钱包的存在使得区块链收发资金成为可能。区块链钱包同时也是web3.0的一个重要入口，事实上，web3的绝大多数应用，必须要连接区块链钱包才能进一步使用\n根据钱包的存储方式划分&emsp;根据用户是否掌握了私钥，可分为中心化钱包 和 去中心化钱包\n\n\n存储方式是指存在哪，只有用户持有私钥且导入钱包后，私钥存在用户设备上后才叫中心化钱包，中心化钱包的数据依赖于服务商自己的账本，交易所就是一个典型的中心化钱包，在交易所内完成的交易，就是交易所在自己的账本上增加记录，这个过程，没有发生在链上。&emsp;而无私钥，或者私钥存储在服务商的服务器里，则就是去中心化钱包，\n\n\n根据是否接触网络&emsp;钱包是否联网可分为冷钱包 和 热钱包\n\n\n常见的热钱包指的是桌面钱包: 如 比特币核心钱包、Geth, 手机钱包，imToken、TpToken等，以及网页钱包, 如 metamask ,而冷钱包指的是硬件钱包，无需联网即可使用，冷钱包外形像U盘。\n\n\n根据去中心化程度&emsp;可将钱包分为全节点钱包、轻节点钱包、中心化钱包\n\n\n全节点钱包：完整储存了区块链一切买卖数据的区块链钱包，一般作为官方钱包与节点客户端运用，能够追溯数字财产的来历，验证数字财产的真实性、验证区块链上的买卖是否完成等，由于全节点钱包存储的数据巨大，且数据需要和区块链同步，因此实用性依赖于具体场景。轻节点钱包：没有彻底存储区块链买卖节点的数据钱包，由于数据不完整，只保留了区块链钱包的基本功能，即接入功能和买卖验证功能，轻钱包所有的功能都是为了支持交易的成功进行，市面上常见的app钱包都是轻钱包：AToken、myToken、Kcash等.\n\n\n根据是否支持多币种&emsp;钱包是否支持多币种可分为 单币种钱包 和 多币种钱包\n\n\n单一币种钱包：只为单一区块链资产服务的钱包，也叫主链钱包，一般由项目方或社区开发。多币种钱包：支持多个区块链的数字资产，全币种钱包：支持所有区块链资产，目前全币种钱包很难存在，这意味该钱包需要支持所有类型区块链协议。市场上的多币种钱包已成为主流。imToken 是依据单ETH主链的多币种钱包，仅支持以ETH协议开发的token。EOSToken 是以EOS主链的钱包, 仅支持EOS协议开发.\n\n\n根据私钥签名方法可分为单签名钱包和多签名钱包\n\n单签名钱包，由单个私钥签名的钱包多签名钱包，需要不同私钥签名进行使用的钱包，一般用于共同管理账户，大多数区块链钱包App都是单签名钱包，Gnosis则是多签名钱包。\n\n\n区块链钱包的设计原理\n私钥、公钥和地址产生的方法\n&emsp; 1.比特币私钥其实是使用SHA-256生成的32字节（256位）的随机数，有效私钥的范围则取决于比特币使用的secp256k1 椭圆曲线数字签名标准。&emsp; 2.在私钥的前面加上版本号，后面添加压缩标志和附加校验码，（所谓附加校验码，就是对私钥经过2次SHA-256运算，取两次哈希结果的前四字节），然后再对其进行Base58编码，就可以得到我们常见的WIF（Wallet import Format)格式的私钥。&emsp; 3.私钥经过椭圆曲线乘法运算，可以得到公钥。公钥是椭圆曲线上的点，并具有x和y坐标。公钥有两种形式：压缩的与非压缩的。早期比特币均使用非压缩公钥，现在大部分客户端默认使用压缩公钥。&emsp; 从私钥推导出公钥、再从公钥推导出公钥哈希都是单向的，也就是采用不可逆算法\n\n\n\n椭圆曲线算法\n\n\n&emsp; 4.公钥产生后，将公钥通过SHA256哈希算法处理得到32字节的哈希值；后对得到的哈希值通过RIPEMD-160算法来得到20字节的哈希值 ——Hash160&emsp; 5.把版本号[2]+Hash160组成的21字节数组进行双次SHA256哈希运算，得到的哈希值的头4个字节作为校验和，放置21字节数组的末尾。&emsp; 6.对组成25位数组进行Base58编码，最后得到地址。\n\n\n\n使用区块链API进行远程调用&gt;&gt;常见的一些钱包开源项目：[bitcoin]Bitcoin Core，官方出品bitcoinj，比特币协议 Java 版bither，简单安全的比特币钱包Electrum，全平台轻钱包bread，iOS 钱包Mycelium，Android 钱包Copay，同时支持 Bitcoin 和BitcoinCashbitcoin-wallet，又一款 Android 钱包DotNetWallet，.NET 实现的钱包Coinpunk，基于浏览器的钱包btcwallet，Go 实现的钱包[Ethereum&#x2F;ERC20]go-ethereum，以太坊协议 Go 版Mist，官方出品Parity，支持 Windows、Mac、PC 的钱包MetaMask chrome浏览器eth wallet插件MyEtherWallet，基于浏览器的钱包eth-lightwallet，轻量级 JavasSript 版本钱包ethaddress.org，纸质版钱包生成器Neureal wallet，支持 Windows、Mac、PC 的钱包\n\n钱包设计：助记词、keystore、密码\n\n\n私钥一般太难记忆了，使用也不方便，所以从钱包设计的角度，就为简化操作同时不丢失安全性，就出现了助记词的方法。一般情况下，助记词由一些单词组成，只要你记住这些单词，按照顺序在钱包中输入，也能打开钱包。根据密钥之间是否有关联，将钱包分为 nondeterministic wallet 和 deterministic walletnondeterministic wallet: 密钥对之间没有关联。deterministic wallet： 密钥由一个原始的种子主密钥推导而来，常见的推导方式就是树状层级推导，(hierarchical deterministic) 简称HDdeterministic wallet 基于BIP32标准实现，通过一个共同的种子维护多对私钥，推导私钥的过程采用不可逆哈希算法，\n\n\n\n\n生成助记词\n\n规定熵的位数必须是 32 的整数倍，所以熵的长度取值位128 到 256 之间取 32 的整数倍的值，分别为 128, 160, 192, 224, 256；校验和的长度为熵的长度&#x2F;32 位, 所以校验和长度可为 4，5，6，7，8 位；助记词库有 2048 个词，用 11 位可全部定位词库中所有的词，作为词的索引，故一个词用 11 位表示，助记词的个数可为 (熵+校验和)&#x2F;11，值为 12，15，18，21，24助记词规则:1.生成一个长度为 128~256 位(bits)的随机序列(熵)；2.取熵哈希后的前n位作为校验和(n&#x3D; 熵长度&#x2F;32)；3.随机序列+校验和；4.把步骤3得到的结果每 11位切割；5.步骤4得到的每11位字节匹配词库的一个词；6.步骤5得到的结果就是助记词串;7.助记词句子作为密码；8.”mnemonic” + passphrase 作为盐；9.2048 作为重复计算的次数+HMAC-SHA512 作为随机算法,最终得到BIP32 种子，512 位(64 字节)是期望得到的密钥长度；\n\n除了助记词之外，钱包还会设计一个密码，作为用户常用的登录方式，keystore：Keystore也是私钥经过加密过后的一个文件，需要你自己设置的密码才能打开文件。这样的好处是就算keystore文件被盗，只要你额外设置的密码够长够随机，那么短时间内私钥也不会泄露，有充足的时间转移地址里面的加密货币到其他地址。Keystore会存储在使用的设备里，这样每次登陆只用输入相应密码即可。\n总结\n\n钱包助记词生成了种子（Seed），种子（Seed）生成了私钥，私钥推导出公钥，公钥节选部分成了钱包地址。同时钱包提供了keystore，他也是私钥加密后的文件，可以配合正常的密码使用，便捷了用户的钱包使用\n\n[私钥重复问题]私钥产生的机制就决定了会有重复的可能。\n\n&emsp; 私钥有32个字节，一个字节有8位，所以私钥总数是2^(8*32)&#x3D;2^256个≈10^77个假设宇宙有一亿个星系，每个星系有一亿颗恒星，每颗恒星有一亿颗人造卫星，每颗人造卫星上有一亿台超级计算机，每台超级计算机有一亿个CPU，每个CPU每秒可以穷举一亿个私钥。假设有一亿个私钥的地址上有BTC（每个地址平均0.21BTC），那么，多久可能穷举出一个有币的私钥为：10^77（私钥总数）&#x2F;10^8（有币私钥）&#x2F;10^8（星系）&#x2F;10^8（恒星）&#x2F;10^8（卫星）&#x2F;10^8（超级计算机）&#x2F;10^8（CPU）&#x2F;10^8（每秒穷举）&#x3D;10^21秒。10^21秒&#x2F;3600秒&#x2F;24小时&#x2F;365天&#x3D;317098亿年随着时间的累积，再加上还会有其他的公链出现，如果使用同样的私钥生成地址的规则，概率再小也会有几率出现重复的情况。但是穷举法的代价已经远远超过了所获利，因此可以理解私钥是唯一的。\n\n理解钱包的作用\n完成一次交易之后，钱包里没有币，也没有NFT，钱包里保存的是自己的区块链地址和对这个地址的操作权限，这些我们交易得到的币、NFT、或者其他什么加密资产是被记录在了各个网络上的对应的区块链中。可以说，钱包是区块链的遥控器，创建钱包时，用助记词算出私钥，私钥和公钥配对出现，公钥算出地址，地址就是你在区块链中的账号，助记词可以重新算出私钥，可重置钱包，同时钱包生成的keystore也可以解密后获得私钥，用于重置钱包。私钥的作用是获得对地址的操作权限。钱包地址可以看作区块链上的一个节点。发起交易，是通过私钥授权，对地址对应的数据区块进行修改。\n\n"}]